{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fdb467-788c-4b6b-a27a-a0f9c4e1d8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CALIBRATION STEP 1: COLOR ---\n",
      "Are the plates COLORED (e.g., blue, red, yellow)? Press 'y' or 'n'.\n",
      "Now, draw a box around the plate, then press ENTER.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.pairwise import cosine_similarity # (Available, but BFMatcher is used)\n",
    "\n",
    "# ============ PCA-Deep-SIFT-HOG Descriptor ============\n",
    "class DeepHOGDescriptor:\n",
    "    def __init__(self, n_components=3, patch_size=64, device=\"cuda\"):\n",
    "        self.device = device if torch.cuda.is_available() else \"cpu\"\n",
    "        print(f\"DeepDescriptor using device: {self.device}\")\n",
    "        self.model = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features[:16].to(self.device).eval()\n",
    "        self.pca = PCA(n_components=n_components)\n",
    "        self.patch_size = patch_size\n",
    "        self.trained = False\n",
    "\n",
    "    def fit_pca(self, gray_images):\n",
    "        patches = []\n",
    "        for g in gray_images:\n",
    "            h, w = g.shape\n",
    "            if h <= self.patch_size or w <= self.patch_size:\n",
    "                print(f\"Skipping frame in fit_pca, too small: {g.shape}\")\n",
    "                continue\n",
    "                \n",
    "            for _ in range(20):  # sample 20 random patches per frame\n",
    "                try:\n",
    "                    x = np.random.randint(self.patch_size // 2, w - self.patch_size // 2)\n",
    "                    y = np.random.randint(self.patch_size // 2, h - self.patch_size // 2)\n",
    "                    patch = g[y - self.patch_size // 2: y + self.patch_size // 2,\n",
    "                              x - self.patch_size // 2: x + self.patch_size // 2]\n",
    "                    patches.append(patch)\n",
    "                except ValueError:\n",
    "                    print(f\"Warning: Could not sample patch from frame of size {g.shape}\")\n",
    "                    break\n",
    "        \n",
    "        if not patches:\n",
    "            print(\"‚ö†Ô∏è Warning: No patches sampled to train PCA. Descriptor may fail.\")\n",
    "            return\n",
    "\n",
    "        feats = []\n",
    "        for p in patches:\n",
    "            p_resized = cv2.resize(p, (self.patch_size, self.patch_size))\n",
    "            t = torch.tensor(p_resized / 255.).float().unsqueeze(0).unsqueeze(0).repeat(1, 3, 1, 1).to(self.device)\n",
    "            \n",
    "            with torch.inference_mode():\n",
    "                fmap = self.model(t).detach().cpu().numpy()[0]\n",
    "            \n",
    "            feats.append(fmap.reshape(fmap.shape[0], -1).mean(axis=1))\n",
    "\n",
    "        if feats:\n",
    "            self.pca.fit(np.vstack(feats))\n",
    "            self.trained = True\n",
    "            print(f\"‚úÖ PCA fitted on {len(patches)} random sample patches.\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Warning: Could not extract features to train PCA.\")\n",
    "\n",
    "    def extract(self, gray_patch):\n",
    "        if not self.trained:\n",
    "            return None\n",
    "        \n",
    "        if gray_patch.shape[0] != self.patch_size or gray_patch.shape[1] != self.patch_size:\n",
    "            gray_patch = cv2.resize(gray_patch, (self.patch_size, self.patch_size))\n",
    "\n",
    "        t = torch.tensor(gray_patch / 255.).float().unsqueeze(0).unsqueeze(0).repeat(1, 3, 1, 1).to(self.device)\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            fmap = self.model(t).detach().cpu().numpy()[0]\n",
    "\n",
    "        fmap_flat = fmap.reshape(fmap.shape[0], -1).T\n",
    "        \n",
    "        try:\n",
    "            fmap_pca = self.pca.transform(fmap_flat)\n",
    "        except Exception as e:\n",
    "            print(f\"PCA transform failed: {e}\")\n",
    "            return None\n",
    "\n",
    "        fmap_pca = fmap_pca.T\n",
    "        hogs = []\n",
    "        \n",
    "        winSize = (self.patch_size, self.patch_size)\n",
    "        blockSize = (16, 16)\n",
    "        blockStride = (8, 8)\n",
    "        cellSize = (8, 8)\n",
    "        nbins = 9\n",
    "        hog = cv2.HOGDescriptor(winSize, blockSize, blockStride, cellSize, nbins)\n",
    "\n",
    "        for ch in fmap_pca:\n",
    "            img = (ch - np.min(ch)) / (np.ptp(ch) + 1e-8)\n",
    "            img = (img * 255).astype(np.uint8)\n",
    "            img_resized_for_hog = cv2.resize(img, (self.patch_size, self.patch_size))\n",
    "            \n",
    "            hvec = hog.compute(img_resized_for_hog)\n",
    "            if hvec is not None:\n",
    "                hogs.append(hvec.flatten())\n",
    "        \n",
    "        if len(hogs) == 0: return None\n",
    "        desc = np.concatenate(hogs)\n",
    "        desc /= (np.linalg.norm(desc) + 1e-8)\n",
    "        return desc\n",
    "\n",
    "# ============ End Descriptor Class ============\n",
    "\n",
    "\n",
    "# --------- RPE Helper (Bench Press Specific) ---------\n",
    "def bench_velocity_to_rpe(velocity_mps: float) -> float:\n",
    "    \"\"\"\n",
    "    Estimate RPE for bench press based on last-rep bar velocity (m/s).\n",
    "    Source: VBT research (S√°nchez-Medina & Gonz√°lez-Badillo, 2011, etc.)\n",
    "    \"\"\"\n",
    "    if velocity_mps >= 0.45:\n",
    "        return 6.0    # ~RPE 6‚Äì7\n",
    "    elif velocity_mps >= 0.35:\n",
    "        return 7.0    # ~RPE 7‚Äì8\n",
    "    elif velocity_mps >= 0.25:\n",
    "        return 8.0    # ~RPE 8.5‚Äì9\n",
    "    elif velocity_mps >= 0.15:\n",
    "        return 9.0    # ~RPE 9‚Äì9.5\n",
    "    else:\n",
    "        return 10.0   # failure / grind\n",
    "\n",
    "\n",
    "# --------- Calibration Helper ---------\n",
    "plate_diameter_real = 0.45  # meters\n",
    "points = []\n",
    "scale = None\n",
    "px_to_m = None\n",
    "frame_resized = None # Declare globally for the callback\n",
    "\n",
    "def click_event(event, x, y, flags, param):\n",
    "    global points, frame_resized, scale, px_to_m\n",
    "    if event == cv2.EVENT_LBUTTONDOWN and len(points) < 2:\n",
    "        points.append((x, y))\n",
    "        cv2.circle(frame_resized, (x, y), 5, (0, 0, 255), -1)\n",
    "        cv2.imshow(\"Click Plate Diameter\", frame_resized)\n",
    "\n",
    "        if len(points) == 2:\n",
    "            (x1, y1), (x2, y2) = points\n",
    "            dist_px_resized = np.linalg.norm(np.array([x2-x1, y2-y1]))\n",
    "            dist_px_original = dist_px_resized / scale\n",
    "            px_to_m = plate_diameter_real / dist_px_original\n",
    "\n",
    "            print(f\"üëâ Plate diameter in resized frame: {dist_px_resized:.1f} px\")\n",
    "            print(f\"üëâ Plate diameter in original frame: {dist_px_original:.1f} px\")\n",
    "            print(f\"üëâ Scale: {px_to_m:.6f} m/px\")\n",
    "\n",
    "            cv2.line(frame_resized, (x1,y1), (x2,y2), (0,255,0), 2)\n",
    "            cv2.imshow(\"Click Plate Diameter\", frame_resized)\n",
    "\n",
    "\n",
    "# --------- Setup ---------\n",
    "video_path = \"bench2.mp4\" # <-- Corrected video path\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Could not open video file: {video_path}\")\n",
    "    \n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "if fps == 0:\n",
    "    fps = 30\n",
    "delay = int(1000 / fps)\n",
    "\n",
    "# --- Calibration (Now 2 steps) ---\n",
    "ret, frame = cap.read()\n",
    "if not ret:\n",
    "    raise RuntimeError(\"Could not read video for calibration\")\n",
    "\n",
    "# Resize for screen\n",
    "max_w, max_h = 1280, 720\n",
    "h, w = frame.shape[:2]\n",
    "scale = min(max_w / w, max_h / h)\n",
    "new_w, new_h = int(w * scale), int(h * scale)\n",
    "frame_resized = cv2.resize(frame, (new_w, new_h))\n",
    "\n",
    "# --- CALIBRATION STEP 1: COLOR (NEW) ---\n",
    "print(\"--- CALIBRATION STEP 1: COLOR ---\")\n",
    "print(\"Are the plates COLORED (e.g., blue, red, yellow)? Press 'y' or 'n'.\")\n",
    "# Create a window to capture key press\n",
    "cv2.imshow(\"Color Check\", frame_resized)\n",
    "key = cv2.waitKey(0) & 0xFF\n",
    "is_colored = True if key == ord('y') else False\n",
    "cv2.destroyWindow(\"Color Check\")\n",
    "\n",
    "print(\"Now, draw a box around the plate, then press ENTER.\")\n",
    "roi = cv2.selectROI(\"Select Plate (Draw Box)\", frame_resized, fromCenter=False, showCrosshair=True)\n",
    "cv2.destroyWindow(\"Select Plate (Draw Box)\")\n",
    "\n",
    "if roi[2] == 0 or roi[3] == 0:\n",
    "    raise RuntimeError(\"Calibration failed. You must draw a box.\")\n",
    "\n",
    "roi_patch = frame_resized[int(roi[1]):int(roi[1]+roi[3]), int(roi[0]):int(roi[0]+roi[2])]\n",
    "hsv_roi = cv2.cvtColor(roi_patch, cv2.COLOR_BGR2HSV)\n",
    "avg, std = cv2.meanStdDev(hsv_roi)\n",
    "\n",
    "if is_colored:\n",
    "    h_avg = avg[0][0]\n",
    "    h_range = 15 # Hue range\n",
    "    lower_hsv = np.array([max(0, h_avg - h_range), 40, 40]) # Min Sat and Val\n",
    "    upper_hsv = np.array([min(179, h_avg + h_range), 255, 255])\n",
    "    print(f\"‚úÖ COLOR mode. Hue center: {h_avg:.0f}, Range: [{lower_hsv[0]}, {upper_hsv[0]}]\")\n",
    "else:\n",
    "    # Grayscale/Metallic mode. Filter by low Saturation and Value range.\n",
    "    v_avg = avg[2][0]\n",
    "    v_std = std[2][0]\n",
    "    # Target low saturation (0-50) and a dynamic value range\n",
    "    lower_hsv = np.array([0, 0, max(0, v_avg - 2*v_std)])\n",
    "    upper_hsv = np.array([179, 50, min(255, v_avg + 2*v_std)])\n",
    "    print(f\"‚úÖ GRAYSCALE mode. Value center: {v_avg:.0f}, Saturation: < 50\")\n",
    "\n",
    "print(f\"Using HSV range: {lower_hsv} to {upper_hsv}\")\n",
    "# --- END COLOR CALIBRATION ---\n",
    "\n",
    "\n",
    "# --- CALIBRATION STEP 2: SCALE (Original) ---\n",
    "cv2.imshow(\"Click Plate Diameter\", frame_resized)\n",
    "cv2.setMouseCallback(\"Click Plate Diameter\", click_event)\n",
    "print(\"\\n--- CALIBRATION STEP 2: SCALE ---\")\n",
    "print(\"Click on the top and bottom of a 45cm plate, then press any key.\")\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyWindow(\"Click Plate Diameter\")\n",
    "\n",
    "if px_to_m is None:\n",
    "    raise RuntimeError(\"Calibration not done. Please click on the plate diameter.\")\n",
    "# --- END SCALE CALIBRATION ---\n",
    "\n",
    "\n",
    "# --- Descriptor Setup ---\n",
    "USE_DEEP_DESCRIPTOR = True  # This must be True to run\n",
    "\n",
    "if USE_DEEP_DESCRIPTOR:\n",
    "    print(\"Initializing DeepHOGDescriptor...\")\n",
    "    deep_descriptor = DeepHOGDescriptor(n_components=3, patch_size=64)\n",
    "    \n",
    "    # Use the same video, reset cap\n",
    "    cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "    frames_for_pca = []\n",
    "    for _ in range(10):\n",
    "        ret, f = cap.read() # <-- FIXED: Use cap, not cap_tmp\n",
    "        if not ret: break\n",
    "        frames_for_pca.append(cv2.cvtColor(f, cv2.COLOR_BGR2GRAY))\n",
    "    # <-- FIXED: Removed cap_tmp.release()\n",
    "    \n",
    "    if frames_for_pca:\n",
    "        deep_descriptor.fit_pca(frames_for_pca)\n",
    "    else:\n",
    "        print(\"Error: Could not read frames to fit PCA.\")\n",
    "        USE_DEEP_DESCRIPTOR = False\n",
    "        \n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "else:\n",
    "    raise RuntimeError(\"Deep descriptor is disabled ‚Äî enable USE_DEEP_DESCRIPTOR = True to run.\")\n",
    "\n",
    "last_good_desc = None # Used for Pass 1 re-detection only\n",
    "\n",
    "# --- HSV + Tracker Setup ---\n",
    "# 'lower_hsv' and 'upper_hsv' are now set dynamically during calibration\n",
    "tracker = None\n",
    "tracking = False\n",
    "bar_path = []\n",
    "max_path_length = 40\n",
    "last_center = None\n",
    "frames_since_lost = 0\n",
    "max_lost_frames = 5\n",
    "\n",
    "# --- Kalman Filter Setup ---\n",
    "kf = cv2.KalmanFilter(4, 2)\n",
    "kf.measurementMatrix = np.array([[1, 0, 0, 0], [0, 1, 0, 0]], np.float32)\n",
    "kf.transitionMatrix = np.array([[1, 0, 1, 0], [0, 1, 0, 1], [0, 0, 1, 0], [0, 0, 0, 1]], np.float32)\n",
    "kf.processNoiseCov = np.eye(4, dtype=np.float32) * 0.03\n",
    "\n",
    "# --- Analysis Variables ---\n",
    "fps_list_pass1 = []\n",
    "redetection_count_pass1 = 0\n",
    "fps_list_pass2 = []\n",
    "redetection_count_pass2 = 0\n",
    "avg_fps = 0 # For on-screen display\n",
    "MASTER_ANCHOR_DESC = None \n",
    "\n",
    "# --------- PASS 1: Backend Scan (lock thresholds) ---------\n",
    "print(\"üîç Backend scan running to prime state...\")\n",
    "# Reset video to start\n",
    "cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "frame_count = 0\n",
    "bar_min_y, bar_max_y = None, None\n",
    "in_bottom_position = False\n",
    "rep_start_frame, rep_start_y = None, None\n",
    "locked_min_y, locked_max_y = None, None\n",
    "tracker, tracking, last_center, frames_since_lost, last_good_desc = None, False, None, 0, None\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    frame_count += 1\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    bar_y = None\n",
    "\n",
    "    if tracking:\n",
    "        success, box = tracker.update(frame)\n",
    "        if success:\n",
    "            x, y, w_box, h_box = [int(v) for v in box]\n",
    "            cx, cy = x + w_box // 2, y + h_box // 2\n",
    "            roi = hsv[max(0, y):y + h_box, max(0, x):x + w_box]\n",
    "            if roi.size == 0:\n",
    "                frames_since_lost += 1\n",
    "            else:\n",
    "                mask_roi = cv2.inRange(roi, lower_hsv, upper_hsv)\n",
    "                visible_ratio = cv2.countNonZero(mask_roi) / (w_box * h_box + 1e-6)\n",
    "                if visible_ratio < 0.15: # ‚ö†Ô∏è You may also need to tune this visibility ratio\n",
    "                    frames_since_lost += 1\n",
    "                else:\n",
    "                    frames_since_lost = 0\n",
    "                    if w_box > 0 and h_box > 0:\n",
    "                        roi_gray = gray[y:y + h_box, x:x + w_box]\n",
    "                        if roi_gray.size > 0:\n",
    "                            if USE_DEEP_DESCRIPTOR:\n",
    "                                patch_resized = cv2.resize(roi_gray, (deep_descriptor.patch_size, deep_descriptor.patch_size))\n",
    "                                desc = deep_descriptor.extract(patch_resized)\n",
    "                                if desc is not None:\n",
    "                                    last_good_desc = np.array([desc], dtype=np.float32)\n",
    "                            \n",
    "                    meas = np.array([[np.float32(cx)], [np.float32(cy)]])\n",
    "                    kf.predict()\n",
    "                    est = kf.correct(meas)\n",
    "                    scx, scy = int(est[0]), int(est[1])\n",
    "                    last_center = (scx, scy)\n",
    "                    bar_y = scy\n",
    "\n",
    "        if frames_since_lost > max_lost_frames:\n",
    "            redetection_count_pass1 += 1\n",
    "            tracking = False\n",
    "            tracker = None\n",
    "            frames_since_lost = 0\n",
    "\n",
    "    if not tracking:\n",
    "        mask = cv2.inRange(hsv, lower_hsv, upper_hsv)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        candidate_contours = []\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            # ‚ö†Ô∏è Tune these contour filters for your bench press plates\n",
    "            if 300 < area < 8000: \n",
    "                peri = cv2.arcLength(cnt, True)\n",
    "                if peri == 0: continue\n",
    "                circ = 4 * np.pi * area / (peri ** 2)\n",
    "                if 0.4 < circ < 1.3: # Check for circularity\n",
    "                    candidate_contours.append((circ, cnt))\n",
    "        best_contour = None\n",
    "        if len(candidate_contours) == 1:\n",
    "            best_contour = candidate_contours[0][1]\n",
    "        elif len(candidate_contours) > 1 and last_good_desc is not None:\n",
    "            max_matches = 0\n",
    "            best_candidate = None\n",
    "            for circ, cnt in candidate_contours:\n",
    "                x_c, y_c, w_c, h_c = cv2.boundingRect(cnt)\n",
    "                roi_c = gray[y_c:y_c + h_c, x_c:x_c + w_c]\n",
    "                if roi_c.size == 0: continue\n",
    "                \n",
    "                desc_c = None \n",
    "                if USE_DEEP_DESCRIPTOR:\n",
    "                    patch_resized_c = cv2.resize(roi_c, (deep_descriptor.patch_size, deep_descriptor.patch_size))\n",
    "                    desc_c_vec = deep_descriptor.extract(patch_resized_c)\n",
    "                    if desc_c_vec is not None:\n",
    "                        desc_c = np.array([desc_c_vec], dtype=np.float32)\n",
    "\n",
    "                if desc_c is not None and len(desc_c) > 0:\n",
    "                    try:\n",
    "                        matches = bf.match(last_good_desc, desc_c)\n",
    "                        if len(matches) > max_matches:\n",
    "                            max_matches = len(matches)\n",
    "                            best_candidate = cnt\n",
    "                    except cv2.error:\n",
    "                        continue\n",
    "            best_contour = best_candidate\n",
    "        elif len(candidate_contours) > 1:\n",
    "            candidate_contours.sort(key=lambda x: x[0], reverse=True)\n",
    "            best_contour = candidate_contours[0][1]\n",
    "\n",
    "        if best_contour is not None:\n",
    "            x, y, w_box, h_box = cv2.boundingRect(best_contour)\n",
    "            tracker = cv2.legacy.TrackerCSRT_create()\n",
    "            tracker.init(frame, (x, y, w_box, h_box))\n",
    "            tracking = True\n",
    "            last_center = (x + w_box // 2, y + h_box // 2)\n",
    "            bar_y = last_center[1]\n",
    "            kf.statePost = np.array([[last_center[0]], [last_center[1]], [0], [0]], dtype=np.float32)\n",
    "            roi_gray_init = gray[y:y + h_box, x:x + w_box]\n",
    "            if roi_gray_init.size > 0:\n",
    "                \n",
    "                if USE_DEEP_DESCRIPTOR:\n",
    "                    patch_resized_init = cv2.resize(roi_gray_init, (deep_descriptor.patch_size, deep_descriptor.patch_size))\n",
    "                    desc_init = deep_descriptor.extract(patch_resized_init)\n",
    "                    if desc_init is not None:\n",
    "                        desc_init_arr = np.array([desc_init], dtype=np.float32)\n",
    "                        last_good_desc = desc_init_arr # For Pass 1 re-detection\n",
    "                        \n",
    "                        # --- MODIFICATION: SAVE ANCHOR IMAGES ---\n",
    "                        if MASTER_ANCHOR_DESC is None:\n",
    "                            MASTER_ANCHOR_DESC = desc_init_arr\n",
    "                            print(\"‚úÖ Master Deep-HOG Anchor Descriptor has been captured.\")\n",
    "                            \n",
    "                            try:\n",
    "                                cv2.imwrite(\"anchor_patch_custom_64x64.jpg\", patch_resized_init)\n",
    "                                frame_with_box = frame.copy()\n",
    "                                cv2.rectangle(frame_with_box, (x, y), (x + w_box, y + h_box), (0, 255, 0), 3)\n",
    "                                cv2.putText(frame_with_box, \"MASTER ANCHOR\", (x, y - 10), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 1.0, (0, 255, 0), 2)\n",
    "                                cv2.imwrite(\"anchor_full_frame_custom.jpg\", frame_with_box)\n",
    "                                print(\"üì∏ Saved 'anchor_patch_custom_64x64.jpg' and 'anchor_full_frame_custom.jpg'\")\n",
    "                            except Exception as e:\n",
    "                                print(f\"Error saving anchor images: {e}\")\n",
    "                        # --- END MODIFICATION ---\n",
    "\n",
    "    # --- Rep Logic (Pass 1) ---\n",
    "    if bar_y is not None:\n",
    "        if bar_min_y is None: bar_min_y, bar_max_y = bar_y, bar_y\n",
    "        bar_min_y = min(bar_min_y, bar_y) # lockout\n",
    "        bar_max_y = max(bar_max_y, bar_y) # chest\n",
    "        range_y = bar_max_y - bar_min_y\n",
    "        \n",
    "        if range_y > 20: # ‚ö†Ô∏è Tune this pixel range if needed\n",
    "            top_threshold = bar_min_y + 0.2 * range_y\n",
    "            bottom_threshold = bar_max_y - 0.2 * range_y\n",
    "            if bar_y > bottom_threshold:\n",
    "                in_bottom_position = True\n",
    "            elif in_bottom_position:\n",
    "                rep_start_frame, rep_start_y = frame_count, bar_y\n",
    "                in_bottom_position = False\n",
    "            if rep_start_frame is not None and bar_y < top_threshold:\n",
    "                rep_end_frame = frame_count\n",
    "                rep_time = (rep_end_frame - rep_start_frame) / fps\n",
    "                displacement_m = abs((rep_start_y - bar_y) * px_to_m)\n",
    "                if rep_time > 0.1:\n",
    "                    velocity = displacement_m / rep_time\n",
    "                    rpe = bench_velocity_to_rpe(velocity) \n",
    "                    print(f\"‚úÖ Backend rep detected: Vel={velocity:.3f} m/s, RPE={rpe}\")\n",
    "                    locked_min_y, locked_max_y = bar_min_y, bar_max_y\n",
    "                    break # Found anchor and thresholds, exit Pass 1\n",
    "    \n",
    "    # --- FPS Calc ---\n",
    "    end_time = time.time()\n",
    "    frame_time = end_time - start_time\n",
    "    if frame_time > 0:\n",
    "        fps_list_pass1.append(1 / frame_time)\n",
    "\n",
    "# --- End of Pass 1 ---\n",
    "cap.release() # Release cap after Pass 1 is done\n",
    "\n",
    "if locked_min_y is None:\n",
    "    print(\"‚ö†Ô∏è Warning: Could not detect a full rep. Rep counting may be inaccurate.\")\n",
    "    if bar_min_y is not None:\n",
    "        locked_min_y, locked_max_y = bar_min_y, bar_max_y\n",
    "    else:\n",
    "        raise RuntimeError(\"No barbell detected in video at all.\")\n",
    "\n",
    "if MASTER_ANCHOR_DESC is None:\n",
    "    print(\"‚ö†Ô∏è Warning: Could not capture a master anchor. Re-detection may be unstable.\")\n",
    "\n",
    "# --------- PASS 2: Main Playback ---------\n",
    "print(\"üé• Starting main playback...\")\n",
    "cap = cv2.VideoCapture(video_path) # Re-open cap for Pass 2\n",
    "if not cap.isOpened():\n",
    "    raise RuntimeError(f\"Could not re-open video file for Pass 2: {video_path}\")\n",
    "    \n",
    "rep_count, last_rep_velocity, est_rpe = 0, None, None\n",
    "frame_count = 0\n",
    "in_bottom_position = False\n",
    "rep_start_frame, rep_start_y = None, None\n",
    "tracker, tracking, last_center, frames_since_lost = None, False, None, 0\n",
    "bar_path.clear()\n",
    "\n",
    "while cap.isOpened():\n",
    "    start_time = time.time()\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    frame_count += 1\n",
    "    \n",
    "    hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    bar_y = None\n",
    "    box_to_draw = None\n",
    "\n",
    "    if tracking:\n",
    "        success, box = tracker.update(frame)\n",
    "        if success:\n",
    "            x, y, w_box, h_box = [int(v) for v in box]\n",
    "            box_to_draw = (x, y, w_box, h_box)\n",
    "            cx, cy = x + w_box // 2, y + h_box // 2\n",
    "            roi = hsv[max(0, y):y + h_box, max(0, x):x + w_box]\n",
    "            if roi.size == 0:\n",
    "                frames_since_lost += 1\n",
    "            else:\n",
    "                mask_roi = cv2.inRange(roi, lower_hsv, upper_hsv)\n",
    "                visible_ratio = cv2.countNonZero(mask_roi) / (w_box * h_box + 1e-6)\n",
    "                if visible_ratio < 0.15: # ‚ö†Ô∏è Tune this\n",
    "                    frames_since_lost += 1\n",
    "                else:\n",
    "                    frames_since_lost = 0\n",
    "                    meas = np.array([[np.float32(cx)], [np.float32(cy)]])\n",
    "                    kf.predict()\n",
    "                    est = kf.correct(meas)\n",
    "                    scx, scy = int(est[0]), int(est[1])\n",
    "                    last_center = (scx, scy)\n",
    "                    bar_y = scy\n",
    "                    bar_path.append(last_center)\n",
    "                    if len(bar_path) > max_path_length: bar_path.pop(0)\n",
    "                    cv2.rectangle(frame, (x, y), (x + w_box, y + h_box), (0, 255, 0), 2)\n",
    "\n",
    "        if frames_since_lost > max_lost_frames:\n",
    "            redetection_count_pass2 += 1\n",
    "            tracking = False\n",
    "            tracker = None\n",
    "            frames_since_lost = 0\n",
    "\n",
    "    if not tracking:\n",
    "        mask = cv2.inRange(hsv, lower_hsv, upper_hsv)\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, np.ones((5, 5), np.uint8))\n",
    "        mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, np.ones((5, 5), np.uint8))\n",
    "        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        candidate_contours = []\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if 300 < area < 8000: # ‚ö†Ô∏è Tune this\n",
    "                peri = cv2.arcLength(cnt, True)\n",
    "                if peri == 0: continue\n",
    "                circ = 4 * np.pi * area / (peri ** 2)\n",
    "                if 0.4 < circ < 1.3: # ‚ö†Ô∏è Tune this\n",
    "                    candidate_contours.append((circ, cnt))\n",
    "        best_contour = None\n",
    "        if len(candidate_contours) == 1:\n",
    "            best_contour = candidate_contours[0][1]\n",
    "        \n",
    "        elif len(candidate_contours) > 1 and MASTER_ANCHOR_DESC is not None:\n",
    "            max_matches = 0\n",
    "            best_candidate = None\n",
    "            for circ, cnt in candidate_contours:\n",
    "                x_c, y_c, w_c, h_c = cv2.boundingRect(cnt)\n",
    "                roi_c = gray[y_c:y_c + h_c, x_c:x_c + w_c]\n",
    "                if roi_c.size == 0: continue\n",
    "                \n",
    "                desc_c = None\n",
    "                if USE_DEEP_DESCRIPTOR:\n",
    "                    patch_resized_c = cv2.resize(roi_c, (deep_descriptor.patch_size, deep_descriptor.patch_size))\n",
    "                    desc_c_vec = deep_descriptor.extract(patch_resized_c)\n",
    "                    if desc_c_vec is not None:\n",
    "                        desc_c = np.array([desc_c_vec], dtype=np.float32)\n",
    "\n",
    "                if desc_c is not None and len(desc_c) > 0:\n",
    "                    try:\n",
    "                        matches = bf.match(MASTER_ANCHOR_DESC, desc_c)\n",
    "                        if len(matches) > max_matches:\n",
    "                            max_matches = len(matches)\n",
    "                            best_candidate = cnt\n",
    "                    except cv2.error:\n",
    "                        continue\n",
    "            best_contour = best_candidate\n",
    "        elif len(candidate_contours) > 1:\n",
    "            candidate_contours.sort(key=lambda x: x[0], reverse=True)\n",
    "            best_contour = candidate_contours[0][1]\n",
    "            \n",
    "        if best_contour is not None:\n",
    "            x, y, w_box, h_box = cv2.boundingRect(best_contour)\n",
    "            box_to_draw = (x, y, w_box, h_box)\n",
    "            tracker = cv2.legacy.TrackerCSRT_create()\n",
    "            tracker.init(frame, (x, y, w_box, h_box))\n",
    "            tracking = True\n",
    "            last_center = (x + w_box // 2, y + h_box // 2)\n",
    "            bar_y = last_center[1]\n",
    "            kf.statePost = np.array([[last_center[0]], [last_center[1]], [0], [0]], dtype=np.float32)\n",
    "            cv2.rectangle(frame, (x, y), (x + w_box, y + h_box), (0, 255, 0), 2)\n",
    "\n",
    "    # --- Draw Bar Path ---\n",
    "    for i in range(1, len(bar_path)):\n",
    "        if bar_path[i-1] is not None and bar_path[i] is not None:\n",
    "            cv2.line(frame, bar_path[i - 1], bar_path[i], (0, 255, 255), 3)\n",
    "\n",
    "    # --- Rep detection using locked thresholds ---\n",
    "    if bar_y and locked_min_y is not None:\n",
    "        top_threshold = locked_min_y + 0.2 * (locked_max_y - locked_min_y)\n",
    "        bottom_threshold = locked_max_y - 0.2 * (locked_max_y - locked_min_y)\n",
    "\n",
    "        if bar_y > bottom_threshold and not in_bottom_position:\n",
    "            in_bottom_position = True\n",
    "            rep_start_frame = None\n",
    "        if in_bottom_position and bar_y < bottom_threshold:\n",
    "            rep_start_frame, rep_start_y = frame_count, bar_y\n",
    "            in_bottom_position = False\n",
    "        if rep_start_frame is not None and bar_y < top_threshold:\n",
    "            rep_end_frame = frame_count\n",
    "            rep_time = (rep_end_frame - rep_start_frame) / fps\n",
    "            if rep_time > 0.1:\n",
    "                displacement_m = abs((rep_start_y - bar_y) * px_to_m)\n",
    "                avg_velocity = displacement_m / rep_time\n",
    "                # <-- FIXED: Call the correct RPE function\n",
    "                last_rep_velocity, est_rpe = avg_velocity, bench_velocity_to_rpe(avg_velocity)\n",
    "                rep_count += 1\n",
    "                print(f\"Rep {rep_count}: Vel={avg_velocity:.3f} m/s, RPE={est_rpe}\")\n",
    "            rep_start_frame = None\n",
    "\n",
    "    # --- Display ---\n",
    "    cv2.putText(frame, f\"Bench Reps: {rep_count}\", (50, 100), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0, 255, 0), 3)\n",
    "\n",
    "    if last_rep_velocity is not None:\n",
    "        # est_rpe is already calculated during rep counting\n",
    "        cv2.putText(frame, f\"Last Rep Vel: {last_rep_velocity:.2f} m/s\", (50, 150),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "        cv2.putText(frame, f\"Est. RPE: {est_rpe}\", (50, 200),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "    \n",
    "    # --- FPS Calc & Display ---\n",
    "    end_time = time.time()\n",
    "    frame_time = end_time - start_time\n",
    "    if frame_time > 0:\n",
    "        current_fps = 1 / frame_time\n",
    "        fps_list_pass2.append(current_fps)\n",
    "        if len(fps_list_pass2) > 10:\n",
    "            avg_fps = sum(fps_list_pass2[-10:]) / 10\n",
    "            \n",
    "    cv2.putText(frame, f\"FPS: {avg_fps:.2f}\", (50, 50),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 0), 2)\n",
    "    \n",
    "    # Resize for display\n",
    "    h_frame, w_frame = frame.shape[:2]\n",
    "    scale_disp = min(max_w / w_frame, max_h / h_frame)\n",
    "    frame_display_resized = cv2.resize(frame, (int(w_frame * scale_disp), int(h_frame * scale_disp)))\n",
    "    \n",
    "    # <-- FIXED: Corrected window title\n",
    "    cv2.imshow(\"Bench Press Tracking\", frame_display_resized)\n",
    "    if cv2.waitKey(delay) & 0xFF == ord('q'): break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 3. Print final report metrics\n",
    "print(\"\\n--- DEEP-HOG CV (ANCHOR): FINAL ANALYSIS ---\")\n",
    "if fps_list_pass1:\n",
    "    print(f\"Pass 1 (Scan) Avg FPS: {sum(fps_list_pass1) / len(fps_list_pass1):.2f}\")\n",
    "    print(f\"Pass 1 (Scan) Re-Detections: {redetection_count_pass1}\")\n",
    "if fps_list_pass2:\n",
    "    print(f\"Pass 2 (Playback) Avg FPS: {sum(fps_list_pass2) / len(fps_list_pass2):.2f}\")\n",
    "    print(f\"Pass 2 (Playback) Re-Detections: {redetection_count_pass2}\")\n",
    "print(\"------------------------------------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24495de8-e356-4514-b4e7-5930fcd64a43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (emotions_env)",
   "language": "python",
   "name": "emotions_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
